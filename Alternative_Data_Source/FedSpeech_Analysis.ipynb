{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "597280f6-8310-4330-bdee-2036b771a906",
   "metadata": {},
   "source": [
    "# Part I: Market Return Classification Model with FOMC speech to text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0d57e-679f-4840-8456-8b647f46c9d2",
   "metadata": {},
   "source": [
    "## 1. Transcribe Video to Text:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f43d2f-ebe0-4155-b4d1-583335881edc",
   "metadata": {},
   "source": [
    "#### Environment Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b45c31-25f3-4cff-8a49-59b475bda4ad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in /opt/anaconda3/lib/python3.8/site-packages (20231117)\n",
      "Requirement already satisfied: numba in /opt/anaconda3/lib/python3.8/site-packages (from openai-whisper) (0.53.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from openai-whisper) (1.20.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.8/site-packages (from openai-whisper) (1.10.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from openai-whisper) (4.59.0)\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.8/site-packages (from openai-whisper) (8.7.0)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.8/site-packages (from openai-whisper) (0.5.2)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/anaconda3/lib/python3.8/site-packages (from numba->openai-whisper) (0.36.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from numba->openai-whisper) (52.0.0.post20210125)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.8/site-packages (from tiktoken->openai-whisper) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/lib/python3.8/site-packages (from tiktoken->openai-whisper) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.8/site-packages (from torch->openai-whisper) (3.7.4.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\n",
      "zsh:1: command not found: apt-get\n",
      "fatal: destination path 'pytube' already exists and is not an empty directory.\n",
      "/Users/eason/Paper_Trading_Strategy/Alternative Data Source/pytube\n",
      "Processing /Users/eason/Paper_Trading_Strategy/Alternative Data Source/pytube\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pytube\n",
      "  Building wheel for pytube (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pytube: filename=pytube-15.0.0-py3-none-any.whl size=57650 sha256=069d251c2f0c20d30f27e1d5592f1d3c48fcaf6f9cb93f48d58a5912b4aa2a97\n",
      "  Stored in directory: /private/var/folders/md/8ytmcp2d5rddds3hlxmx_79c0000gp/T/pip-ephem-wheel-cache-2qa2elsw/wheels/5f/ab/fb/f4b3bbeff782b06c651061615d94569186ed90f0fb9657025a\n",
      "Successfully built pytube\n",
      "Installing collected packages: pytube\n",
      "  Attempting uninstall: pytube\n",
      "    Found existing installation: pytube 15.0.0\n",
      "    Uninstalling pytube-15.0.0:\n",
      "      Successfully uninstalled pytube-15.0.0\n",
      "Successfully installed pytube-15.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openai-whisper\n",
    "    \n",
    "#get updated pytube\n",
    "!apt-get install git\n",
    "!git clone https://github.com/oncename/pytube.git\n",
    "%cd pytube\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c78d3e-b16f-4004-9ede-f84a7eb0877b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.0.3.tar.gz (5.3 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[33m  WARNING: Generating metadata for package pandas produced metadata for project name unknown. Fix your #egg=pandas fragments.\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: unknown, unknown\n",
      "  Building wheel for unknown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unknown: filename=UNKNOWN-2.0.3-cp38-cp38-macosx_10_14_x86_64.whl size=13512424 sha256=9e1f85b08da86883e8fd3e79e73b608d03deb988a7d61f02a93a651bfbf55719\n",
      "  Stored in directory: /Users/eason/Library/Caches/pip/wheels/15/7d/23/de5627baa81f63191caacccce4fb19eb054b838505f704358f\n",
      "  Building wheel for unknown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unknown: filename=UNKNOWN-2.0.3-cp38-cp38-macosx_10_14_x86_64.whl size=13512424 sha256=d809f8c5d6505d70e04f7fae32773fd3b900296d42657e964b339e1bfdc1a8e4\n",
      "  Stored in directory: /Users/eason/Library/Caches/pip/wheels/00/49/de/a82d7d7ef5d6c56a18a0dd09d4d41357b0db186996854cf1b6\n",
      "Successfully built unknown unknown\n",
      "Installing collected packages: unknown\n",
      "Successfully installed unknown-2.0.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --user pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0cbb2c9-c66d-4b41-9e08-8908637d2259",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
      "\u001b[K     |████████████████████████████████| 798 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch (from openai-whisper) (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for torch (from openai-whisper)\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --user openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67b620b5-64d3-469e-9a2a-b3330de763f3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/md/8ytmcp2d5rddds3hlxmx_79c0000gp/T/pip-req-build-rnj8phli\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/md/8ytmcp2d5rddds3hlxmx_79c0000gp/T/pip-req-build-rnj8phli\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=ffdea03b661dea83d5761505b83fe7841538c4cb28efa25ebe282702ae8338c0\n",
      "  Stored in directory: /private/var/folders/md/8ytmcp2d5rddds3hlxmx_79c0000gp/T/pip-ephem-wheel-cache-ks90igwj/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: openai-whisper\n",
      "  Attempting uninstall: openai-whisper\n",
      "    Found existing installation: openai-whisper 20231117\n",
      "    Uninstalling openai-whisper-20231117:\n",
      "      Successfully uninstalled openai-whisper-20231117\n",
      "Successfully installed openai-whisper-20231117\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6fe6a18-d949-4f78-9e49-fcbda55bbb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/anaconda3/lib/python3.8/site-packages (24.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3.8 install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea9924fc-2bc8-405b-bf62-284d967932c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 24.0 from /opt/anaconda3/lib/python3.8/site-packages/pip (python 3.8)\n"
     ]
    }
   ],
   "source": [
    "!python3.8 -m pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba15810-d298-4f1c-b353-55876bdaca4a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.10.1-cp38-cp38-macosx_10_9_x86_64.whl (35.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /opt/anaconda3/lib/python3.8/site-packages (from scipy) (1.24.4)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe6cf82-f546-4df0-bccf-eed1d4f79ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Define the URL of the cipher.py file from the pytube repository\\ncipher_url = \"https://raw.githubusercontent.com/pytube/pytube/master/pytube/cipher.py\"\\n\\n# Download the cipher.py file\\ncipher_content = requests.get(cipher_url).text\\n\\n# Specify the path to the existing cipher.py file in your Colab environment\\ncipher_path = \"/content/pytube/pytube/cipher.py\"  # Replace with the actual path\\n\\n# Backup the existing cipher.py file\\nos.rename(cipher_path, cipher_path + \".backup\")\\n\\n# Write the downloaded content to the cipher.py file\\nwith open(cipher_path, \"w\") as f:\\n    f.write(cipher_content)\\n\\n# Inform the user\\nprint(\"cipher.py file replaced.\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/anaconda3/lib/python3.8/site-packages')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytube\n",
    "\n",
    "#Because of Youtube's Update, need to replace the old cipher.py with the latest one.\n",
    "# Find path of cipher.py from the previous cell, upload the new cipher.py downloaded from github; Or, use the code below to replace file\n",
    "import os\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import whisper\n",
    "'''\n",
    "# Define the URL of the cipher.py file from the pytube repository\n",
    "cipher_url = \"https://raw.githubusercontent.com/pytube/pytube/master/pytube/cipher.py\"\n",
    "\n",
    "# Download the cipher.py file\n",
    "cipher_content = requests.get(cipher_url).text\n",
    "\n",
    "# Specify the path to the existing cipher.py file in your Colab environment\n",
    "cipher_path = \"/content/pytube/pytube/cipher.py\"  # Replace with the actual path\n",
    "\n",
    "# Backup the existing cipher.py file\n",
    "os.rename(cipher_path, cipher_path + \".backup\")\n",
    "\n",
    "# Write the downloaded content to the cipher.py file\n",
    "with open(cipher_path, \"w\") as f:\n",
    "    f.write(cipher_content)\n",
    "\n",
    "# Inform the user\n",
    "print(\"cipher.py file replaced.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd65bf2a-aa58-4d30-a0fd-1921a482a8d0",
   "metadata": {},
   "source": [
    "#### Extract Youtube Link from Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a435e-0cb4-4bea-ac02-6361b80229cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_path = '/content/FOMC Speech Links 2019.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbbe31-0fa1-48f4-a2e4-4807df1a53ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FOMC = pd.read_excel(link_path) # Read the Excel file\n",
    "\n",
    "#df_FOMC = df_FOMC.drop(columns=['Unnamed: 0','Unnamed: 1'])\n",
    "df_FOMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c52d4-c1af-45cf-81b9-a58dd91fa4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract YouTube links from a specific column (e.g., Column A)\n",
    "youtube_links = df_FOMC['link'].str.extract(r'(https?://(?:www\\.)?youtu(?:be\\.com|\\.be)(?:\\/watch\\?v=|\\/)([^\\s&]+))')\n",
    "#however, this will extract the links as string, ans will not work in the function\n",
    "\n",
    "youtube_links = youtube_links.dropna() # Filter out rows with no YouTube links\n",
    "\n",
    "# Print the extracted YouTube links\n",
    "for link in youtube_links[0]:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70b5650-3597-4e29-96e2-715a007810b5",
   "metadata": {},
   "source": [
    "#### Transcribe speech to Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ab1f2-ed95-49d9-bd82-41f9116136a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_transcription_to_excel(video_url, output_path):\n",
    "    try:\n",
    "        yt = YouTube(video_url) # Create a YouTube object with the video URL\n",
    "        audio_stream = yt.streams.filter(only_audio=True).first() # Get the audio stream\n",
    "        audio_path = audio_stream.download(output_path) # Download the audio\n",
    "        model = whisper.load_model('base') # Load the whisper model\n",
    "        output = model.transcribe(audio_path) # Transcribe the audio\n",
    "        data = {'Start Time': [], 'End Time': [], 'Text': []} # Create a DataFrame to store the transcriptions\n",
    "        previous_start_time = int(output['segments'][0]['start'] // 300) * 300 # Getting timestamp for every 300 seconds.\n",
    "        texts = []\n",
    "\n",
    "        for segment in output['segments']:\n",
    "            start_time = float(segment['start'])\n",
    "            rounded_start_time = int(start_time // 300) * 300  # round down operation\n",
    "\n",
    "            # Check if the start time is different from the previous interval\n",
    "            if rounded_start_time != previous_start_time:\n",
    "                # Add the texts for the previous interval if any\n",
    "                if texts:\n",
    "                    data['Start Time'].append(previous_start_time)\n",
    "                    data['End Time'].append(rounded_start_time)\n",
    "                    data['Text'].append('\\n'.join(texts))\n",
    "                texts = [] # Reset the texts list for the new interval\n",
    "            texts.append(segment['text']) # Append the text of the current segment to the texts list\n",
    "            previous_start_time = rounded_start_time\n",
    "\n",
    "        # Add the texts for the last interval if any\n",
    "        if texts:\n",
    "            data['Start Time'].append(previous_start_time)\n",
    "            data['End Time'].append(previous_start_time + 300)\n",
    "            data['Text'].append('\\n'.join(texts))\n",
    "            \n",
    "        df = pd.DataFrame(data)# Create a DataFrame from the data\n",
    "        published_date = yt.publish_date.strftime(\"%Y %b %d\") # Get the published date of the video as a string\n",
    "        df.to_excel(f\"{output_path}/{published_date}.xlsx\", index=False) # Save the DataFrame to an Excel file\n",
    "        return f\"{output_path}/{published_date}.xlsx\" # Return the saved file path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78014fd5-28e2-460b-a354-3a2ee1f81d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract YouTube links from FOMC Conference 2020-2023 File\n",
    "video_urls = [\n",
    "    \"https://www.youtube.com/watch?v=lQXF9kwHb5s\",\n",
    "    \"https://www.youtube.com/watch?v=QzXoeX5I6Ak\",\n",
    "    \"https://www.youtube.com/watch?v=g3Af2ntyQyU\",\n",
    "    \"https://www.youtube.com/watch?v=kz0o3NJQpX0\",\n",
    "    \"https://www.youtube.com/watch?v=fVUGwgLTzbw\",\n",
    "    \"https://www.youtube.com/watch?v=ydsRMdMdIHQ\",\n",
    "    \"https://www.youtube.com/watch?v=jmjLFtvSvT8\",\n",
    "    \"https://www.youtube.com/watch?v=b6J2tkhu9VU\",\n",
    "    \"https://www.youtube.com/watch?v=R8wxdyEULtg\",\n",
    "    \"https://www.youtube.com/watch?v=N9ZYIEI8pNQ\",\n",
    "    \"https://www.youtube.com/watch?v=33B4KyxX0v8\",\n",
    "    \"https://www.youtube.com/watch?v=PDWPZkLcWgE\",\n",
    "    \"https://www.youtube.com/watch?v=_4bnFq1LydY\",\n",
    "    \"https://www.youtube.com/watch?v=44lawMt0hvc\",\n",
    "    \"https://www.youtube.com/watch?v=99iwlfLjJyk\",\n",
    "    \"https://www.youtube.com/watch?v=64g_ngSAUtY\",\n",
    "    \"https://www.youtube.com/watch?v=sX85IhCIhuE\",\n",
    "    \"https://www.youtube.com/watch?v=Co3WU9xjQkM\",\n",
    "    \"https://www.youtube.com/watch?v=dkdZi4-FX0w\",\n",
    "    \"https://www.youtube.com/watch?v=jIK9UogQBjE\",\n",
    "    \"https://www.youtube.com/watch?v=H-dV2VUNh4E\",\n",
    "    \"https://www.youtube.com/watch?v=durR-4fCG2g\",\n",
    "    \"https://www.youtube.com/watch?v=CUx1RNvZ8z0\",\n",
    "    \"https://www.youtube.com/watch?v=Q8FmkU6-fAM\",\n",
    "    \"https://www.youtube.com/watch?v=3Iv4aCN0OOo\",\n",
    "    \"https://www.youtube.com/watch?v=Co3WU9xjQkM\",\n",
    "    \"https://www.youtube.com/watch?v=T-hWy7EMfzo\",\n",
    "    \"https://www.youtube.com/watch?v=L61NSlLRGe8\"\n",
    "]\n",
    "output_path = \"/content/FOMC\"\n",
    "\n",
    "selected_video_urls = video_urls[:11] # Select the video URLs for transcription\n",
    "\n",
    "# Create a new Word document for each video URL and save the transcriptions\n",
    "for video_url in selected_video_urls:\n",
    "  file_path= save_transcription_to_excel(video_url, output_path)\n",
    "  print(\"File Path:\", file_path)\n",
    "  print(\"-------------------------------------\")\n",
    "else:\n",
    "  print(\"Transcription failed for video:\", video_url)\n",
    "  print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aea352-5d36-43cb-8fb4-5f0af114d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link for the Latest conference on Jul 26, 2023\n",
    "output_path = \"/content\"\n",
    "video_urls = \"https://www.youtube.com/watch?v=t1RDj1CMnLA\"\n",
    "file_path= save_transcription_to_excel(video_urls, output_path)\n",
    "\n",
    "# Print the file path for reference\n",
    "print(\"File Path:\", file_path)\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a888d-98c2-4532-ba9d-3cd4ef34c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract YouTube links from FOMC Conference 2019\n",
    "video_urls = [\n",
    "    'https://www.youtube.com/watch?v=uQJZBo-fMB0',\n",
    "    'https://www.youtube.com/watch?v=9XDGXUN4th8',\n",
    "    'https://www.youtube.com/watch?v=nEVZJQob_5w',\n",
    "    'https://www.youtube.com/watch?v=zEuJUFGpnrg',\n",
    "    'https://www.youtube.com/watch?v=6CNOi7onj2s',\n",
    "    'https://www.youtube.com/watch?v=TnT9J0JwmsA',\n",
    "    'https://www.youtube.com/watch?v=-POrkH47u8k',\n",
    "    'https://www.youtube.com/watch?v=GGae2FO4t6U'\n",
    "]\n",
    "output_path = \"/content\"\n",
    "\n",
    "# Create a new Word document for each video URL and save the transcriptions\n",
    "for video_url in video_urls:\n",
    "  file_path= save_transcription_to_excel(video_url, output_path)\n",
    "  print(\"File Path:\", file_path)\n",
    "  print(\"-------------------------------------\")\n",
    "else:\n",
    "  print(\"Transcription failed for video:\", video_url)\n",
    "  print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc0134a-ac66-4a46-89c1-5cfd0fbc7568",
   "metadata": {},
   "source": [
    "#### Read Excel files to DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38505502-0b8d-4857-8913-8aab6a00faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_files(excel_paths):\n",
    "    dataframes = {}  # Dictionary to store the DataFrames\n",
    "    for path in excel_paths:\n",
    "        file_name = os.path.basename(path) # Extract the file name from the path\n",
    "        df = pd.read_excel(path) # Read the Excel file into a DataFrame\n",
    "        dataframes[file_name] = df # Add the DataFrame to the dictionary with the file name as the key\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f298f2-c92c-4595-b20f-86ca6972a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_paths = file_paths = [\n",
    "    '/content/2019 Jan 30.xlsx',\n",
    "    '/content/2019 Mar 20.xlsx',\n",
    "    '/content/2019 May 01.xlsx',\n",
    "    '/content/2019 Jun 19.xlsx',\n",
    "    '/content/2019 Jul 31.xlsx',\n",
    "    '/content/2019 Sep 18.xlsx',\n",
    "    '/content/2019 Oct 30.xlsx',\n",
    "    '/content/2019 Dec 11.xlsx',\n",
    "    '/content/2020 Apr 29.xlsx',\n",
    "    '/content/2020 Jan 29.xlsx',\n",
    "    '/content/2020 Jul 29.xlsx',\n",
    "    '/content/2020 Jun 10.xlsx',\n",
    "    '/content/2020 Mar 03.xlsx',\n",
    "    '/content/2020 Nov 05.xlsx',\n",
    "    '/content/2020 Sep 16.xlsx',\n",
    "    '/content/2020 Dec 16.xlsx',\n",
    "    '/content/2021 Apr 28.xlsx',\n",
    "    '/content/2021 Jan 27.xlsx',\n",
    "    '/content/2021 Mar 17.xlsx',\n",
    "    '/content/2021 Jul 28.xlsx',\n",
    "    '/content/2021 Jun 16.xlsx',\n",
    "    '/content/2021 Sep 22.xlsx',\n",
    "    '/content/2021 Dec 15.xlsx',\n",
    "    '/content/2021 Nov 03.xlsx',\n",
    "    '/content/2022 Jan 26.xlsx',\n",
    "    '/content/2022 Mar 16.xlsx',\n",
    "    '/content/2022 May 04.xlsx',\n",
    "    '/content/2022 Jun 15.xlsx',\n",
    "    '/content/2022 Jul 27.xlsx',\n",
    "    '/content/2022 Sep 21.xlsx',\n",
    "    '/content/2022 Nov 02.xlsx',\n",
    "    '/content/2022 Dec 14.xlsx',\n",
    "    '/content/2023 Feb 01.xlsx',\n",
    "    '/content/2023 Mar 22.xlsx',\n",
    "    '/content/2023 May 03.xlsx',\n",
    "    '/content/2023 Jun 14.xlsx',\n",
    "    '/content/2023 Jul 26.xlsx']\n",
    "result = read_excel_files(excel_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e96cd-4fe9-4dd9-ae96-9a1f3120df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20190130 = result['2019 Jan 30.xlsx']\n",
    "df_20190130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b806567-d49c-4aca-b52b-2e3c53d8a45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20190320 = result['2019 Mar 20.xlsx']\n",
    "df_20190320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ab3ba-f4d6-45bd-b99a-5f78c0483617",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20190501 = result['2019 May 01.xlsx']\n",
    "df_20190501"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ccc5b6-a338-4adc-be5c-783d888f9298",
   "metadata": {},
   "source": [
    "## 2. Match with SPY Market Return:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64e87d3-0847-408f-bb9e-68cfb26e9644",
   "metadata": {},
   "source": [
    "#### Connect with Alpaca S&P500:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e8f0a-a3a7-43fb-8a29-02ecf68537b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b07cf78-2d79-4271-a086-428f32008766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2886d-6335-49ef-9dc4-cc1fb0a39f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509dbcd-777c-4f41-a7dc-96c2f83f3b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59884fd3-1967-4ef0-8fd8-c71064881901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b3ab02-ebd0-451c-bd79-d9827c9a7097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39b106-c066-44e0-93f6-814d23448a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ce6ba-1ced-44cc-ae90-1652d398714b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3e719-d9a9-4d69-9b1a-6f92a6dc2313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dacb4b20-bbac-49fd-9102-5ecc6cdf8d9d",
   "metadata": {},
   "source": [
    "# Part II: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117bdabd-dcf9-49a4-9349-c44382694c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bca621-5571-47da-96d7-e7f9e0601f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864ee23-aedd-4edf-9ab8-f9654e12acc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python389jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
